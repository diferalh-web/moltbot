# ğŸŒ Interfaz Web para Moltbot

## ğŸ“‹ Opciones Disponibles

### OpciÃ³n 1: Open WebUI (Recomendado) â­

**Open WebUI** es una interfaz web moderna tipo ChatGPT que se conecta directamente a Ollama.

#### Ventajas:
- âœ… Interfaz moderna y fÃ¡cil de usar
- âœ… Historial de conversaciones
- âœ… Soporte para mÃºltiples modelos
- âœ… Subida de documentos (RAG)
- âœ… Guardado de prompts favoritos
- âœ… Funciona directamente con Ollama (no necesita Moltbot)

#### ConfiguraciÃ³n:

**En PowerShell de Windows (como Administrador):**

```powershell
.\scripts\setup-open-webui.ps1
```

O manualmente:

```powershell
docker run -d `
  --name open-webui `
  -p 3000:8080 `
  -v ${env:USERPROFILE}/open-webui-data:/app/backend/data `
  --add-host=host.docker.internal:host-gateway `
  -e OLLAMA_BASE_URL=http://host.docker.internal:11436 `
  --restart unless-stopped `
  --gpus all `
  ghcr.io/open-webui/open-webui:main
```

#### Acceso:

1. Abre en tu navegador: `http://localhost:3000`
2. Crea una cuenta (primera vez)
3. Selecciona el modelo "mistral" en la interfaz
4. Â¡Listo para usar!

### OpciÃ³n 2: Interfaz Web Simple Personalizada

Si prefieres una interfaz mÃ¡s simple o personalizada, puedo crear una interfaz web bÃ¡sica que se conecte a Moltbot.

#### CaracterÃ­sticas:
- Interfaz HTML simple
- ConexiÃ³n directa a Moltbot vÃ­a API
- DiseÃ±o minimalista
- FÃ¡cil de personalizar

Â¿Quieres que cree esta opciÃ³n?

### OpciÃ³n 3: Usar el Gateway de Moltbot

Moltbot tiene un gateway que puede exponer una API. Podemos configurarlo y crear una interfaz web que se conecte a Ã©l.

## ğŸš€ RecomendaciÃ³n

**Para tu caso, recomiendo Open WebUI** porque:
1. Ya tienes Ollama-Mistral funcionando con GPU
2. Open WebUI se conecta directamente a Ollama
3. No necesitas configurar Moltbot adicionalmente
4. Interfaz profesional lista para usar

## ğŸ“ Pasos RÃ¡pidos

1. **Ejecutar script de configuraciÃ³n:**
   ```powershell
   .\scripts\setup-open-webui.ps1
   ```

2. **Abrir en navegador:**
   ```
   http://localhost:3000
   ```

3. **Crear cuenta y empezar a usar**

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Cambiar el puerto

Si el puerto 3000 estÃ¡ ocupado, cambia a otro:

```powershell
docker run -d --name open-webui -p 8080:8080 ...  # Cambia 3000 por 8080
```

### Conectar a Qwen en lugar de Mistral

Cambia la variable de entorno:
```powershell
-e OLLAMA_BASE_URL=http://host.docker.internal:11437  # Qwen
```

### Acceso desde la VM

Si quieres acceder desde la VM, usa la IP del host:
```
http://192.168.100.42:3000
```

## ğŸ› Troubleshooting

**Error: Puerto 3000 ocupado**
- Cambia el puerto en el comando docker run

**Error: No se conecta a Ollama**
- Verifica que ollama-mistral estÃ© corriendo: `docker ps | findstr mistral`
- Verifica que el puerto 11436 estÃ© accesible

**Error: No carga la interfaz**
- Espera 30-60 segundos despuÃ©s de crear el contenedor
- Verifica logs: `docker logs open-webui`

---

**Â¿Quieres que ejecute el script de configuraciÃ³n ahora?**












