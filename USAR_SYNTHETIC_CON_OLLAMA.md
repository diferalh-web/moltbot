# âœ… Usar Synthetic con Ollama

## ğŸ’¡ Idea

**Synthetic** es "Anthropic-compatible (multi-model)" y puede funcionar con Ollama ya que Ollama tiene una API compatible.

## âœ… Paso 1: Seleccionar Synthetic

**En el prompt actual:**
- Usa las flechas `â†‘` `â†“` para moverte a "Synthetic"
- Presiona `Enter` para seleccionar

## ğŸ“‹ Paso 2: ConfiguraciÃ³n Esperada

DespuÃ©s de seleccionar Synthetic, probablemente te preguntarÃ¡:

1. **API Endpoint** o **Base URL**:
   - Escribe: `http://192.168.100.42:11435`

2. **API Key** (si pregunta):
   - Ollama no requiere API key real
   - Puedes escribir: `ollama` o `dummy`
   - O presionar `Enter` para omitir

3. **Model Name** (si pregunta):
   - Escribe: `llama2`

## ğŸ”§ Paso 3: Si Pregunta por Modelo EspecÃ­fico

**Si te muestra opciones de modelos:**
- Busca "llama2" en la lista
- O escribe "llama2" directamente

## âœ… Paso 4: Verificar ConfiguraciÃ³n

**DespuÃ©s de que termine la configuraciÃ³n:**

```bash
# Ver agentes
pnpm start agents list

# Ver configuraciÃ³n del agente
cat ~/.openclaw/agents/main/agent/auth-profiles.json
```

## ğŸ§ª Paso 5: Probar

```bash
cd ~/moltbot
pnpm start agent --session-id test-session --message "hola" --local
```

## ğŸ” Si No Funciona Directamente

**Si Synthetic no acepta Ollama directamente, podemos editar el archivo despuÃ©s:**

```bash
nano ~/.openclaw/agents/main/agent/auth-profiles.json
```

**Y modificar para apuntar a Ollama:**

```json
{
  "synthetic": {
    "baseURL": "http://192.168.100.42:11435",
    "apiKey": "ollama",
    "model": "llama2"
  }
}
```

---

**Selecciona "Synthetic" ahora y ve quÃ© opciones te da. Es una buena idea porque es multi-model y compatible con Anthropic.**












