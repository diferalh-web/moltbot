# üîß Soluci√≥n: No Veo Modelos en Open WebUI

## ‚úÖ Verificaci√≥n R√°pida

He verificado que:
- ‚úÖ Open WebUI est√° corriendo
- ‚úÖ Todos los servicios Ollama est√°n accesibles
- ‚úÖ Los modelos est√°n disponibles:
  - `mistral:latest` (puerto 11436)
  - `qwen2.5:7b` (puerto 11437)
  - `codellama:34b` (puerto 11438)
  - `deepseek-coder:33b` (puerto 11438)

## üéØ Soluci√≥n: Configurar en la Interfaz Web

Open WebUI a veces no detecta autom√°ticamente los modelos. Sigue estos pasos:

### Paso 1: Acceder a Configuraci√≥n

1. Abre `http://localhost:8082` en tu navegador
2. **Inicia sesi√≥n** (si no lo has hecho)
3. Busca el **√≠cono de engranaje (‚öôÔ∏è)** en la esquina superior derecha
4. Haz clic en √©l para abrir **Settings** o **Configuraci√≥n**

### Paso 2: Configurar Conexi√≥n a Ollama

1. En el men√∫ lateral, busca **"Connections"** o **"Conexiones"**
2. Busca la secci√≥n de **Ollama**
3. Verifica o configura la URL:
   ```
   http://host.docker.internal:11436
   ```
   O prueba con:
   ```
   http://localhost:11436
   ```

4. Haz clic en **"Test Connection"** o **"Probar Conexi√≥n"**
5. Si funciona, haz clic en **"Save"** o **"Guardar"**

### Paso 3: Recargar y Ver Modelos

1. **Recarga la p√°gina** (presiona `F5` o `Ctrl+R`)
2. Busca el **dropdown "Select a model"** en la parte superior
3. Haz clic en √©l
4. Deber√≠as ver los modelos disponibles

## üîÑ Si Solo Ves un Modelo

Si solo ves `mistral:latest`, puedes agregar los dem√°s modelos manualmente:

### Opci√≥n A: Agregar M√∫ltiples Conexiones Ollama

1. En **Settings ‚Üí Connections**
2. Agrega una nueva conexi√≥n Ollama:
   - **Nombre**: "Ollama-Qwen"
   - **URL**: `http://host.docker.internal:11437`
3. Agrega otra:
   - **Nombre**: "Ollama-Code"
   - **URL**: `http://host.docker.internal:11438`
4. Guarda y recarga

### Opci√≥n B: Usar el Selector de Modelo Manualmente

Si los modelos no aparecen en el dropdown, puedes escribir el nombre del modelo manualmente:

1. En el campo de chat, antes de escribir, busca un bot√≥n o campo para **"Model"**
2. Escribe directamente: `mistral:latest` o `qwen2.5:7b`
3. O usa el formato completo: `ollama/mistral:latest`

## üêõ Troubleshooting

### No veo el √≠cono de engranaje

- Aseg√∫rate de estar **iniciado sesi√≥n**
- Busca en el men√∫ lateral izquierdo
- Puede estar en la parte inferior de la p√°gina

### El "Test Connection" falla

**Verifica en PowerShell:**
```powershell
# Verificar que los servicios est√©n corriendo
docker ps | findstr ollama

# Probar acceso directo
curl http://localhost:11436/api/tags
```

### Los modelos no aparecen despu√©s de recargar

1. **Limpia la cach√© del navegador:**
   - Presiona `Ctrl+Shift+Delete`
   - Selecciona "Cached images and files"
   - Haz clic en "Clear data"

2. **Prueba en modo inc√≥gnito:**
   - Presiona `Ctrl+Shift+N` (Chrome) o `Ctrl+Shift+P` (Firefox)
   - Abre `http://localhost:8082`

3. **Revisa la consola del navegador:**
   - Presiona `F12`
   - Ve a la pesta√±a "Console"
   - Busca errores en rojo

### Reiniciar Open WebUI

Si nada funciona, reinicia el contenedor:

```powershell
docker restart open-webui
```

Espera 30 segundos y vuelve a intentar.

## üìã Modelos Disponibles por Servicio

| Servicio | Puerto | Modelos |
|----------|--------|---------|
| **Ollama-Mistral** | 11436 | `mistral:latest` |
| **Ollama-Qwen** | 11437 | `qwen2.5:7b` |
| **Ollama-Code** | 11438 | `codellama:34b`, `deepseek-coder:33b` |

## üí° Consejos

- **Primera vez**: Puede tardar 10-30 segundos en cargar los modelos
- **Recarga siempre**: Despu√©s de cambiar configuraci√≥n, recarga la p√°gina
- **Un modelo a la vez**: Si tienes problemas, configura solo un servicio Ollama primero
- **Verifica logs**: Si persiste el problema:
  ```powershell
  docker logs open-webui --tail 50
  ```

## üéØ Pr√≥ximos Pasos

Una vez que veas los modelos:

1. **Selecciona un modelo** del dropdown
2. **Escribe tu pregunta** en el campo de texto
3. **Presiona Enter** o haz clic en el bot√≥n de enviar
4. **¬°Disfruta de tu IA local!**

---

**¬øNecesitas ayuda con alg√∫n paso espec√≠fico?** Puedo guiarte paso a paso.












