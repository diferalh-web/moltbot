# C√≥mo Agregar Otros Modelos al Men√∫ de Open WebUI

## ‚úÖ Estado Actual

- **Mistral** ya est√° visible y funcionando en el men√∫ de modelos
- Los otros modelos (Qwen, CodeLlama, DeepSeek-Coder) est√°n corriendo pero no aparecen en el men√∫

## üîß Soluci√≥n: Agregar Modelos Manualmente

Open WebUI requiere agregar los backends adicionales manualmente desde la interfaz web. Sigue estos pasos:

### Paso 1: Acceder a Configuraci√≥n

1. Abre Open WebUI: http://localhost:8082
2. Haz clic en el √≠cono de **Configuraci√≥n** (‚öôÔ∏è) en la parte inferior izquierda
3. Busca la secci√≥n **"Connections"** o **"External Tools"**

### Paso 2: Agregar Cada Backend

Para cada backend, haz clic en **"Add Connection"** o el bot√≥n **"+"** y completa:

#### Backend 1: Qwen
- **Name**: `Qwen`
- **Type**: `Ollama` (o selecciona "Ollama" del dropdown)
- **URL**: `http://localhost:11437`
- **Description** (opcional): `Qwen 2.5 7B - Modelo general chino`

#### Backend 2: Code
- **Name**: `Code`
- **Type**: `Ollama`
- **URL**: `http://localhost:11438`
- **Description** (opcional): `CodeLlama y DeepSeek-Coder - Modelos de programaci√≥n`

#### Backend 3: Flux
- **Name**: `Flux`
- **Type**: `Ollama`
- **URL**: `http://localhost:11439`
- **Description** (opcional): `Flux - Generaci√≥n de im√°genes`

### Paso 3: Verificar Modelos

Despu√©s de agregar cada backend:
1. Espera 10-30 segundos
2. Refresca la p√°gina (F5)
3. Haz clic en el selector de modelos (donde dice "mistral:latest")
4. Deber√≠as ver los nuevos modelos disponibles

## üìã Modelos Disponibles por Backend

### Ollama Mistral (puerto 11436) - ‚úÖ Ya visible
- `mistral:latest` (7.2B)

### Ollama Qwen (puerto 11437)
- `qwen2.5:7b` (4.7 GB)

### Ollama Code (puerto 11438)
- `codellama:34b` (19 GB)
- `deepseek-coder:33b` (18 GB)

### Ollama Flux (puerto 11439)
- (sin modelos a√∫n - puedes descargar Flux m√°s tarde)

## üîç Si No Aparece la Opci√≥n "Connections"

Si no encuentras la secci√≥n "Connections" en Settings:

1. **Verifica la versi√≥n de Open WebUI**: Algunas versiones tienen la opci√≥n en diferentes lugares
2. **Busca "External Tools"**: Puede estar en esa secci√≥n
3. **Revisa "General"**: A veces hay una opci√≥n "Ollama Base URLs" donde puedes agregar m√∫ltiples URLs separadas por comas

## üöÄ Alternativa: Usar Solo Mistral

Si prefieres no configurar manualmente, puedes usar solo **Mistral** que ya est√° funcionando. Mistral es muy vers√°til y puede:
- ‚úÖ Chat general
- ‚úÖ Programaci√≥n (Java, Python, SQL, etc.)
- ‚úÖ Arquitectura y dise√±o
- ‚úÖ Seguridad y ethical hacking
- ‚úÖ Cloud computing
- ‚úÖ IA/ML

## üõ†Ô∏è Soluci√≥n T√©cnica Avanzada

Si quieres automatizar esto, puedes modificar directamente la base de datos de Open WebUI:

```powershell
# Acceder a la base de datos SQLite de Open WebUI
docker exec -it open-webui sqlite3 /app/backend/data/webui.db
```

Sin embargo, esto requiere conocer la estructura exacta de la base de datos y puede causar problemas si se hace incorrectamente.

## ‚úÖ Verificaci√≥n

Para verificar que los modelos est√°n disponibles:

```powershell
# Ver modelos en Qwen
curl http://localhost:11437/api/tags

# Ver modelos en Code
curl http://localhost:11438/api/tags

# Ver modelos en Flux
curl http://localhost:11439/api/tags
```

## üìù Notas

- Los modelos pueden tardar 30-60 segundos en aparecer despu√©s de agregar el backend
- Si un modelo no aparece, verifica que el contenedor Ollama correspondiente est√© corriendo
- Aseg√∫rate de que los puertos 11437, 11438, 11439 est√©n accesibles desde tu m√°quina











